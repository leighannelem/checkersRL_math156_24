{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state import State\n",
    "from players import Player, HumanPlayer, RandomPlayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with Human (Untrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Player(\"computer\", exp_rate=1) # fully random\n",
    "p2 = HumanPlayer(\"human\")\n",
    "test_state = State(p1, p2)\n",
    "test_state.play_human()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "TODO: fix winner so that can accurately check if there are any legal moves left... i think it should work now\n",
    "--> maybe replace with an almost-won starting board just so can test\n",
    "\n",
    "TODO: how to evaluate performance of the agent?\n",
    "--> maybe introduce another method and compare them?\n",
    "idk need to do some research on this..\n",
    "\n",
    "TODO: track \"learning curves\"\n",
    "plot cumulative reward, average reward per episode, numper of steps per episode, success rate over time\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Player(\"p1\")\n",
    "p2 = Player(\"p2\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "print(\"training...\")\n",
    "st.play(12000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.savePolicy()\n",
    "p2.savePolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human vs. Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = Player(\"computer\", exp_rate=0) #takes random action 0% of time\n",
    "p1.loadPolicy(\"policy_p1\")\n",
    "\n",
    "p2 = HumanPlayer(\"human\")\n",
    "\n",
    "st = State(p1, p2)\n",
    "st.play_human() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
